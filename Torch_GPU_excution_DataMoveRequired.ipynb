{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torch_GPU_excution_DataMoveRequired.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vfdJ5kz507O",
        "outputId": "b45b05e3-0a2b-4727-8f13-ee59ac236cf0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torch\n",
        "ones = torch.zeros(3, 2) + 1\n",
        "ones"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threes=ones*3\n",
        "threes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPRQHzoh6fuZ",
        "outputId": "b3a2ab86-d04a-4408-a5c1-0d4ab2981fa6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand=torch.rand(2,4)\n",
        "rand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wh7EJ3C7KsY",
        "outputId": "24271c8d-3194-4b2a-f5bc-aa332ff845a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1692, 0.5810, 0.2161, 0.5361],\n",
              "        [0.0867, 0.5647, 0.9753, 0.9766]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doublerand=rand*2\n",
        "print(doublerand.shape)\n",
        "doublerand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XxfX2ki7XCg",
        "outputId": "b8b520fb-b99c-4849-d8df-3199cdd077f0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3384, 1.1619, 0.4323, 1.0723],\n",
              "        [0.1733, 1.1294, 1.9506, 1.9531]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_Lelg_n8j01",
        "outputId": "7557014a-b4e1-4265-f6a3-ec917a13eb96"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v1 = torch.tensor([1., 0., 0.])         # x unit vector\n",
        "v2 = torch.tensor([0., 1., 0.])         # y unit vector\n",
        "print(torch.cross(v2, v1)) # negative of z unit vector (v1 x v2 == -v2 x v1)\n",
        "print(v1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQqkC5OH9Iqg",
        "outputId": "7c89114d-f081-47f8-a7e4-358fe2ce3402"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.,  0., -1.])\n",
            "torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    gpu_rand = torch.rand(2, 2, device='cuda')\n",
        "    print(gpu_rand)\n",
        "else:\n",
        "    print('Sorry, CPU only.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT12_xNbCrOp",
        "outputId": "5d0c01da-76a9-406d-cb40-9d2e31c241de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3888, 0.8747],\n",
            "        [0.9726, 0.3369]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    my_device = torch.device('cuda')\n",
        "else:\n",
        "    my_device = torch.device('cpu')\n",
        "print('Device: {}'.format(my_device))\n",
        "\n",
        "x = torch.rand(2, 3, device=my_device)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA4M3P1DDu3C",
        "outputId": "1cdccf2a-a2fd-4cb6-a23c-b9e6873ae544"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "tensor([[0.0734, 0.3096, 0.5053],\n",
            "        [0.5882, 0.1422, 0.8458]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have an existing tensor living on one device, you can move it to another with the to() method. The following line of code creates a tensor on CPU, and moves it to whichever device handle you acquired in the previous cell.\n",
        "\n",
        "It is important to know that in order to do computation involving two or more tensors, all of the tensors must be on the same device. "
      ],
      "metadata": {
        "id": "x5nA5lBTEi2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.rand(2, 4)\n",
        "print(y)\n",
        "y = y.to(my_device)\n",
        "\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erH5ETTHEF4A",
        "outputId": "4bd9d084-1fd9-49dd-cd0b-99a160b329d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8509, 0.3518, 0.6497, 0.7260],\n",
            "        [0.6426, 0.2894, 0.3083, 0.7293]])\n",
            "tensor([[0.8509, 0.3518, 0.6497, 0.7260],\n",
            "        [0.6426, 0.2894, 0.3083, 0.7293]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may only squeeze() dimensions of extent 1. See above where we try to squeeze a dimension of size 2 in c, and get back the same shape we started with. Calls to squeeze() and unsqueeze() can only act on dimensions of extent 1 because to do otherwise would change the number of elements in the tensor."
      ],
      "metadata": {
        "id": "ZXWtaoI_HjgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(1, 20)\n",
        "a=a.to(my_device) #move data to GPU\n",
        "print(a.shape)\n",
        "print(a)\n",
        "\n",
        "b = a.squeeze(0)\n",
        "print(b.shape)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z10JMvdG9Nq",
        "outputId": "40298dde-bbb5-4f87-9ccc-4caa4f7fa3fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 20])\n",
            "tensor([[0.5873, 0.4226, 0.2610, 0.7966, 0.5074, 0.2427, 0.8231, 0.5592, 0.3040,\n",
            "         0.9747, 0.5377, 0.1433, 0.6375, 0.4927, 0.8456, 0.8243, 0.0516, 0.8355,\n",
            "         0.7255, 0.6365]], device='cuda:0')\n",
            "torch.Size([20])\n",
            "tensor([0.5873, 0.4226, 0.2610, 0.7966, 0.5074, 0.2427, 0.8231, 0.5592, 0.3040,\n",
            "        0.9747, 0.5377, 0.1433, 0.6375, 0.4927, 0.8456, 0.8243, 0.0516, 0.8355,\n",
            "        0.7255, 0.6365], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_me = torch.rand(3, 226, 226)\n",
        "print(batch_me.shape)\n",
        "batch_me.unsqueeze_(0)\n",
        "print(batch_me.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOK9f0qcHaKC",
        "outputId": "4575858a-a93d-4872-e83b-3a6bb9573e93"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 226, 226])\n",
            "torch.Size([1, 3, 226, 226])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes you’ll want to change the shape of a tensor more radically, while still preserving the number of elements and their contents. One case where this happens is at the interface between a convolutional layer of a model and a linear layer of the model - this is common in image classification models. A convolution kernel will yield an output tensor of shape features x width x height, but the following linear layer expects a 1-dimensional input. reshape() will do this for you, provided that the dimensions you request yield the same number of elements as the input tensor has:"
      ],
      "metadata": {
        "id": "CJK1S9npJFoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output3d = torch.rand(6, 20, 20)\n",
        "print(output3d.shape)\n",
        "\n",
        "input1d = output3d.reshape(6 * 20 * 20)\n",
        "print(input1d.shape)\n",
        "\n",
        "# can also call it as a method on the torch module:\n",
        "print(torch.reshape(output3d, (6 * 20 * 20,)).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga2lDIRLE78h",
        "outputId": "a5b5f10b-2876-4f09-c9c4-1f8ee658929c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 20, 20])\n",
            "torch.Size([2400])\n",
            "torch.Size([2400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it can, reshape() will return a view on the tensor to be changed - that is, a separate tensor object looking at the same underlying region of memory. This is important: That means any change made to the source tensor will be reflected in the view on that tensor, unless you clone() it."
      ],
      "metadata": {
        "id": "EXYj7Mc5KViK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "numpy_array = np.ones((2, 3))\n",
        "print(numpy_array)\n",
        "\n",
        "pytorch_tensor = torch.from_numpy(numpy_array) #convert a numpy array into a tensor\n",
        "print(pytorch_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLO40OV9KWqc",
        "outputId": "4954001c-856b-41ba-cd26-6554d48ab5a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]]\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_rand = torch.rand(2, 3)\n",
        "print(pytorch_rand)\n",
        "\n",
        "numpy_rand = pytorch_rand.numpy()  #convert a tensor into a numpy array\n",
        "print(numpy_rand)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyCwzSaMKp1S",
        "outputId": "04ba27c2-7416-4a9f-ba7b-9776f137da75"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6228, 0.9791, 0.9505],\n",
            "        [0.9391, 0.1913, 0.2905]])\n",
            "[[0.62279856 0.97910345 0.95046777]\n",
            " [0.93909144 0.19129813 0.29045784]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to know that these converted objects are using the same underlying memory as their source objects, meaning that changes to one are reflected in the other:"
      ],
      "metadata": {
        "id": "ez73p23dLRXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array[1, 1] = 23\n",
        "print(pytorch_tensor)\n",
        "\n",
        "pytorch_rand[1, 1] = 17\n",
        "print(numpy_rand)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNCQXgH1KqIp",
        "outputId": "4bf5baa7-3dcf-4a7b-dc38-727a3b9d3a3d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  1.,  1.],\n",
            "        [ 1., 23.,  1.]], dtype=torch.float64)\n",
            "[[ 0.62279856  0.97910345  0.95046777]\n",
            " [ 0.93909144 17.          0.29045784]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nqvDY_RdKqPU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}