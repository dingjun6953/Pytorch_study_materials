{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_linearCal_4waysComparisons.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yow1AhHILrzW",
        "outputId": "d3a61046-8914-46fc-f79e-1f4a91dd9ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.214, 6.335, -1.62]\n",
            "[1.214, 6.335, -1.62]\n"
          ]
        }
      ],
      "source": [
        "#using pure Python to calculate W*x+B\n",
        "#there is no any import library/module\n",
        "#  4 inputs into 3 neuron of outputs\n",
        "inputs=[1,2,3,4]\n",
        "weights=[[0.8,-0.76,0.99,-0.514],\n",
        "         [-0.3,-0.45,0.765,0.81],\n",
        "         [0.23,0.38,-0.41,-0.72]]\n",
        "biases=[1.02,2,1.5]\n",
        "output_py=[inputs[0]*weights[0][0]+inputs[1]*weights[0][1]+inputs[2]*weights[0][2]+inputs[3]*weights[0][3]+biases[0],\n",
        "           inputs[0]*weights[1][0]+inputs[1]*weights[1][1]+inputs[2]*weights[1][2]+inputs[3]*weights[1][3]+biases[1],\n",
        "           inputs[0]*weights[2][0]+inputs[1]*weights[2][1]+inputs[2]*weights[2][2]+inputs[3]*weights[2][3]+biases[2],\n",
        "]\n",
        "print(output_py)\n",
        "\n",
        "#if there are many inputs and weights, then coding as follow:\n",
        "layer_outputs=[] #output current layer\n",
        "for neuron_weights, neuron_bias in zip(weights,biases):\n",
        "  neuron_output=0 # output of a given neuron\n",
        "  for n_input,weight in zip(inputs,neuron_weights):\n",
        "    neuron_output += n_input * weight\n",
        "  neuron_output +=neuron_bias\n",
        "  layer_outputs.append(neuron_output)\n",
        "print(layer_outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WhKCOtA5UTX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using Numpy to calculate W*x+B\n",
        "import numpy as np\n",
        "#tensorflow calculats w*x+b via numpy and then convert the result into the tensor\n",
        "import tensorflow as tf\n",
        "inputs=np.array([1,2,3,4])\n",
        "weights=np.array([[0.8,-0.76,0.99,-0.514],\n",
        "         [-0.3,-0.45,0.765,0.81],\n",
        "         [0.23,0.38,-0.41,-0.72]])\n",
        "biases=np.array([1.02,2,1.5])\n",
        "\n",
        "output_np=np.dot(weights,inputs)+biases\n",
        "output_tf=tf.convert_to_tensor(output_np)\n",
        "print(output_np)\n",
        "print(output_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYrEjG74Lsdi",
        "outputId": "3af986e8-70c8-48ed-b3cf-0b6d153807fe"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.214  6.335 -1.62 ]\n",
            "tf.Tensor([ 1.214  6.335 -1.62 ], shape=(3,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using Pytorch to calculate W*x+B\n",
        "import torch\n",
        "\n",
        "inputs=torch.tensor([1.,2.,3.,4.],dtype=torch.float32)\n",
        "weights=torch.tensor([[0.8,-0.76,0.99,-0.514],\n",
        "         [-0.3,-0.45,0.765,0.81],\n",
        "         [0.23,0.38,-0.41,-0.72]],dtype=torch.float32)\n",
        "biases=torch.tensor([1.02,2,1.5],dtype=torch.float32)\n",
        "print(weights.shape)\n",
        "print(inputs.shape)\n",
        "print(biases.shape)\n",
        "inputs=inputs.view(inputs.shape[0],1)\n",
        "biases=biases.view(biases.shape[0],1)\n",
        "print(inputs.shape)\n",
        "print(biases.shape)\n",
        "\n",
        "output_torch=torch.matmul(weights,inputs)+biases\n",
        "print(output_torch)\n",
        "print(output_torch.shape)\n",
        "print(\"after reshape of output_torch\")\n",
        "output_torch=output_torch.view(output_torch.shape[0])\n",
        "print(output_torch)\n",
        "print(output_torch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRg9YkDtLsgR",
        "outputId": "5964c2cf-5eba-4ffe-9baf-7bf77b141d10"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4])\n",
            "torch.Size([4])\n",
            "torch.Size([3])\n",
            "torch.Size([4, 1])\n",
            "torch.Size([3, 1])\n",
            "tensor([[ 1.2140],\n",
            "        [ 6.3350],\n",
            "        [-1.6200]])\n",
            "torch.Size([3, 1])\n",
            "after reshape of output_torch\n",
            "tensor([ 1.2140,  6.3350, -1.6200])\n",
            "torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2, 3)\n",
        "b = torch.rand(3, 2)\n",
        "\n",
        "#print(a * b)\n",
        "print(torch.matmul(a,b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhjiNmq_LsjR",
        "outputId": "75e773d2-9a54-4a06-e40c-c40d9fce7fbf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5915, 0.3654],\n",
            "        [1.2229, 0.6001]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using tensorflow to calculate W*x+B\n",
        "import tensorflow as tf\n",
        "inputs=tf.Variable([[1,2,3,4]],dtype=tf.float32)\n",
        "weights=tf.Variable([[0.8,-0.76,0.99,-0.514],\n",
        "         [-0.3,-0.45,0.765,0.81],\n",
        "         [0.23,0.38,-0.41,-0.72]],dtype=tf.float32)\n",
        "biases=tf.Variable([[1.02,2,1.5]],dtype=tf.float32)\n",
        "print(weights.shape)\n",
        "print(inputs.shape)\n",
        "print(biases.shape)\n",
        "#need to transpose matrix\n",
        "print(tf.transpose(inputs).shape)\n",
        "print(tf.transpose(biases).shape)\n",
        "output_tf=tf.matmul(weights,tf.transpose(inputs))+tf.transpose(biases)\n",
        "print(output_tf)\n",
        "\n",
        "#flatten for vector\n",
        "output_tf_flatten=tf.reshape(output_tf,[-1])\n",
        "print(output_tf_flatten.shape)\n",
        "print(output_tf_flatten)\n",
        "\n",
        "print(\"\\nndim size compared\")\n",
        "print(output_tf.ndim)\n",
        "print(output_tf_flatten.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1uf6SxhLslx",
        "outputId": "1fb13d48-beab-4728-bbaf-0831c321c8a2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 4)\n",
            "(1, 4)\n",
            "(1, 3)\n",
            "(4, 1)\n",
            "(3, 1)\n",
            "tf.Tensor(\n",
            "[[ 1.214    ]\n",
            " [ 6.335    ]\n",
            " [-1.6200001]], shape=(3, 1), dtype=float32)\n",
            "2\n",
            "(3,)\n",
            "tf.Tensor([ 1.214      6.335     -1.6200001], shape=(3,), dtype=float32)\n",
            "\n",
            "ndim size compared\n",
            "2\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
        "b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
        "c = tf.matmul(a, b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFPj6EfrLsra",
        "outputId": "c4597050-8c3e-4933-b5a3-c4e80daa6207"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 58  64]\n",
            " [139 154]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = tf.Variable([[1.], [2.]])\n",
        "x = tf.Variable([[3., 4.]])\n",
        "#x = tf.constant([[3., 4.]])\n",
        "print(w.shape)\n",
        "print(x.shape)\n",
        "tf.matmul(w, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUs2GzpwLsuR",
        "outputId": "f77e4abf-e54c-4696-d723-898140bddff2"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 1)\n",
            "(1, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[3., 4.],\n",
              "       [6., 8.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g-BTqN1oUVDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batches, Layers, and Objects\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "#inputs [3,4], batchsize=3\n",
        "#define hidden layer as an object\n",
        "# The object has 3 features of weights, biases and output\n",
        "# hidden layer size: the 1st hidden layer has 5 neurons and the 2nd hidden layer has 2 output neurons\n",
        "X=[[1.,2.,3.,2.5],\n",
        "   [2.0,5.0,-1,-0.8],\n",
        "   [0.7,1.7,2,9,-3.2]]\n",
        "\n",
        "class Layer_dense:\n",
        "  def __init__(self, n_inputs,n_neurons):\n",
        "    self.weights=0.10*np.random.randn(n_inputs,n_neurons)\n",
        "    self.biases=np.zeros((1,n_neurons))\n",
        "  def forward(self,inputs):\n",
        "    self.output=np.dot(inputs,self.weights)+self.biases\n",
        "  \n",
        "class Activation_Relu:\n",
        "  def forward(self,inputs):\n",
        "    self.output=np.maximum(0,inputs)\n",
        "\n",
        "\n",
        "\n",
        "#you may design the number of hidden layer neurons what you want \n",
        "print(\"\\nThe 1st hidder layer outputs\\n\")\n",
        "layer1=Layer_dense(4,6)\n",
        "activation1=Activation_Relu()\n",
        "layer1.forward(inputs)\n",
        "print(layer1.output)\n",
        "activation1.forward(layer1.output)\n",
        "print(activation1.output)\n",
        "\n",
        "print(\"\\nThe 2nd hidder layer outputs\\n\")\n",
        "\n",
        "layer2=Layer_dense(6,10)\n",
        "activation2=Activation_Relu()\n",
        "layer2.forward(activation1.output)\n",
        "print(layer2.output)\n",
        "activation2.forward(layer2.output)\n",
        "print(activation2.output)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9x_mD3HUVGv",
        "outputId": "bc09d565-ba81-45c9-d8ad-56cdec8fa6b1"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The 1st hidder layer outputs\n",
            "\n",
            "[[ 0.71996132 -0.29539151 -0.81080693  0.66775876  1.00956271 -0.16528657]]\n",
            "[[0.71996132 0.         0.         0.66775876 1.00956271 0.        ]]\n",
            "\n",
            "The 2nd hidder layer outputs\n",
            "\n",
            "[[ 0.17944394 -0.11666877 -0.15684256  0.05344208 -0.0236007   0.08681\n",
            "   0.03985774  0.0162384  -0.00318605 -0.38254713]]\n",
            "[[0.17944394 0.         0.         0.05344208 0.         0.08681\n",
            "  0.03985774 0.0162384  0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CVMVhOR7UVJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Hidden Layer Activation Functions"
      ],
      "metadata": {
        "id": "-A6S-u9wUVM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n892A-b5UVPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "05jpJ--mUVSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aOXp3Tl1UVVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6V0TTzGeUVXv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}