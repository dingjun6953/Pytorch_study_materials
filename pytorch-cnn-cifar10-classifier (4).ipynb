{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#### https://jovian.ai/aakashns/05-cifar10-cnn\n\n# Uncomment and run the appropriate command for your operating system, if required\n\n# Linux / Binder / Windows (No GPU)\n# !pip install numpy matplotlib torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n\n# Linux / Windows (GPU)\n# pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n \n# MacOS (NO GPU)\n# !pip install numpy matplotlib torch torchvision torchaudio","metadata":{"id":"W5VPgfd2aQJ_","execution":{"iopub.status.busy":"2022-07-03T15:06:38.036222Z","iopub.execute_input":"2022-07-03T15:06:38.037157Z","iopub.status.idle":"2022-07-03T15:06:38.058141Z","shell.execute_reply.started":"2022-07-03T15:06:38.037064Z","shell.execute_reply":"2022-07-03T15:06:38.056882Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision\nimport tarfile\nfrom torchvision.datasets.utils import download_url\nfrom torch.utils.data import random_split","metadata":{"id":"0oxgpWkcaXSy","execution":{"iopub.status.busy":"2022-07-03T15:06:38.060113Z","iopub.execute_input":"2022-07-03T15:06:38.060547Z","iopub.status.idle":"2022-07-03T15:06:39.923959Z","shell.execute_reply.started":"2022-07-03T15:06:38.060511Z","shell.execute_reply":"2022-07-03T15:06:39.922984Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"project_name='05-cifar10-cnn'","metadata":{"id":"Wkt_EwayaXZS","execution":{"iopub.status.busy":"2022-07-03T15:06:39.925305Z","iopub.execute_input":"2022-07-03T15:06:39.926709Z","iopub.status.idle":"2022-07-03T15:06:39.930466Z","shell.execute_reply.started":"2022-07-03T15:06:39.926680Z","shell.execute_reply":"2022-07-03T15:06:39.929578Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Dowload the dataset\ndataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\ndownload_url(dataset_url, '.')","metadata":{"id":"YOhIy-uPaXcK","outputId":"a15874aa-b70d-44ef-9b93-4ba5f379f877","execution":{"iopub.status.busy":"2022-07-03T15:06:39.933581Z","iopub.execute_input":"2022-07-03T15:06:39.934663Z","iopub.status.idle":"2022-07-03T15:06:47.924628Z","shell.execute_reply.started":"2022-07-03T15:06:39.934627Z","shell.execute_reply":"2022-07-03T15:06:47.923664Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Extract from archive\nwith tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n    tar.extractall(path='./data')","metadata":{"id":"6LKti-yWaXfB","execution":{"iopub.status.busy":"2022-07-03T15:06:47.926102Z","iopub.execute_input":"2022-07-03T15:06:47.926824Z","iopub.status.idle":"2022-07-03T15:07:00.376921Z","shell.execute_reply.started":"2022-07-03T15:06:47.926786Z","shell.execute_reply":"2022-07-03T15:07:00.375980Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_dir = './data/cifar10'\n\nprint(os.listdir(data_dir))\nclasses = os.listdir(data_dir + \"/train\")\nprint(classes)","metadata":{"id":"eVvUcw2taXhp","outputId":"b4150f8f-6f92-4752-a2ef-303c19d36b60","execution":{"iopub.status.busy":"2022-07-03T15:07:00.378424Z","iopub.execute_input":"2022-07-03T15:07:00.378775Z","iopub.status.idle":"2022-07-03T15:07:00.387602Z","shell.execute_reply.started":"2022-07-03T15:07:00.378739Z","shell.execute_reply":"2022-07-03T15:07:00.385289Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"airplane_files = os.listdir(data_dir + \"/train/airplane\")\nprint('No. of training examples for airplanes:', len(airplane_files))\nprint(airplane_files[:5])","metadata":{"id":"aQwFBxv_aXkq","outputId":"903a0472-319f-49d6-d924-c298c1f9b5a1","execution":{"iopub.status.busy":"2022-07-03T15:07:00.389080Z","iopub.execute_input":"2022-07-03T15:07:00.389675Z","iopub.status.idle":"2022-07-03T15:07:00.401425Z","shell.execute_reply.started":"2022-07-03T15:07:00.389637Z","shell.execute_reply":"2022-07-03T15:07:00.400305Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ship_test_files = os.listdir(data_dir + \"/test/ship\")\nprint(\"No. of test examples for ship:\", len(ship_test_files))\nprint(ship_test_files[:5])","metadata":{"id":"Am8o5C1TaXnp","outputId":"b82869ad-a497-4542-eb72-7ed5005a4467","execution":{"iopub.status.busy":"2022-07-03T15:07:00.403209Z","iopub.execute_input":"2022-07-03T15:07:00.405245Z","iopub.status.idle":"2022-07-03T15:07:00.412148Z","shell.execute_reply.started":"2022-07-03T15:07:00.405209Z","shell.execute_reply":"2022-07-03T15:07:00.410668Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\ndataset = ImageFolder(data_dir+'/train', transform=ToTensor())\nimg, label = dataset[0]\nprint(img.shape, label)\nimg","metadata":{"id":"QRJ9IBLQaXq8","outputId":"216cb450-9b0e-4df8-f86c-7bf1e9a3b88d","execution":{"iopub.status.busy":"2022-07-03T15:07:00.417565Z","iopub.execute_input":"2022-07-03T15:07:00.418178Z","iopub.status.idle":"2022-07-03T15:07:00.655103Z","shell.execute_reply.started":"2022-07-03T15:07:00.418141Z","shell.execute_reply":"2022-07-03T15:07:00.654102Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(dataset.classes)\n","metadata":{"id":"0xIm5zBwaXt7","outputId":"c2a7b981-8802-4585-d4e4-f9a34b6142ee","execution":{"iopub.status.busy":"2022-07-03T15:07:00.656624Z","iopub.execute_input":"2022-07-03T15:07:00.657217Z","iopub.status.idle":"2022-07-03T15:07:00.662488Z","shell.execute_reply.started":"2022-07-03T15:07:00.657179Z","shell.execute_reply":"2022-07-03T15:07:00.661179Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nmatplotlib.rcParams['figure.facecolor'] = '#ffffff'","metadata":{"id":"jGnpKrYWaXw7","execution":{"iopub.status.busy":"2022-07-03T15:07:00.664074Z","iopub.execute_input":"2022-07-03T15:07:00.664664Z","iopub.status.idle":"2022-07-03T15:07:00.673924Z","shell.execute_reply.started":"2022-07-03T15:07:00.664629Z","shell.execute_reply":"2022-07-03T15:07:00.673008Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def show_example(img, label):\n    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n    plt.imshow(img.permute(1, 2, 0))\nshow_example(*dataset[0])\n","metadata":{"id":"RdxBNo_naXzz","outputId":"657a1856-df37-446c-f90d-5ebc97712d50","execution":{"iopub.status.busy":"2022-07-03T15:07:00.675427Z","iopub.execute_input":"2022-07-03T15:07:00.676078Z","iopub.status.idle":"2022-07-03T15:07:00.866520Z","shell.execute_reply.started":"2022-07-03T15:07:00.676042Z","shell.execute_reply":"2022-07-03T15:07:00.865584Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"show_example(*dataset[1099])","metadata":{"id":"VDcPf3XmaX27","outputId":"d73cf738-4455-408e-f436-11c6d5da5862","execution":{"iopub.status.busy":"2022-07-03T15:07:00.867961Z","iopub.execute_input":"2022-07-03T15:07:00.868300Z","iopub.status.idle":"2022-07-03T15:07:01.036576Z","shell.execute_reply.started":"2022-07-03T15:07:00.868264Z","shell.execute_reply":"2022-07-03T15:07:01.035404Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Training and Validation Datasets\nWhile building real world machine learning models, it is quite common to split the dataset into 3 parts:\n\nTraining set - used to train the model i.e. compute the loss and adjust the weights of the model using gradient descent.\nValidation set - used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.\nTest set - used to compare different models, or different types of modeling approaches, and report the final accuracy of the model.\nSince there's no predefined validation set, we can set aside a small portion (5000 images) of the training set to be used as the validation set. We'll use the random_split helper method from PyTorch to do this. To ensure that we always create the same validation set, we'll also set a seed for the random number generator.","metadata":{"id":"b68vt0AvcU3M"}},{"cell_type":"code","source":"random_seed = 3\ntorch.manual_seed(random_seed)","metadata":{"id":"f92HUyMaaX6E","outputId":"7bacbdf3-13ca-4709-abd1-9b40c2e9d094","execution":{"iopub.status.busy":"2022-07-03T15:07:01.038144Z","iopub.execute_input":"2022-07-03T15:07:01.039187Z","iopub.status.idle":"2022-07-03T15:07:01.049488Z","shell.execute_reply.started":"2022-07-03T15:07:01.039146Z","shell.execute_reply":"2022-07-03T15:07:01.048557Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"val_size = 5000\n#val_size = 256\ntrain_size = len(dataset) - val_size\n\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\nlen(train_ds), len(val_ds)","metadata":{"id":"FcwwW38EaX9R","outputId":"b4852290-4c3b-44f4-f045-f903fbab450d","execution":{"iopub.status.busy":"2022-07-03T15:07:01.052301Z","iopub.execute_input":"2022-07-03T15:07:01.054805Z","iopub.status.idle":"2022-07-03T15:07:01.066077Z","shell.execute_reply.started":"2022-07-03T15:07:01.054772Z","shell.execute_reply":"2022-07-03T15:07:01.064854Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data.dataloader import DataLoader\n\nbatch_size=256\n#batch_size=100","metadata":{"id":"G2Ey3u9tctCL","execution":{"iopub.status.busy":"2022-07-03T15:07:01.067672Z","iopub.execute_input":"2022-07-03T15:07:01.068299Z","iopub.status.idle":"2022-07-03T15:07:01.074199Z","shell.execute_reply.started":"2022-07-03T15:07:01.068263Z","shell.execute_reply":"2022-07-03T15:07:01.073086Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size, num_workers=2, pin_memory=True)","metadata":{"id":"yX_oe75QctFD","execution":{"iopub.status.busy":"2022-07-03T15:07:01.075952Z","iopub.execute_input":"2022-07-03T15:07:01.077183Z","iopub.status.idle":"2022-07-03T15:07:01.084568Z","shell.execute_reply.started":"2022-07-03T15:07:01.077152Z","shell.execute_reply":"2022-07-03T15:07:01.083652Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from torchvision.utils import make_grid\n\ndef show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 6))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n        break","metadata":{"id":"ZYuvOwOectH7","execution":{"iopub.status.busy":"2022-07-03T15:07:01.086574Z","iopub.execute_input":"2022-07-03T15:07:01.087816Z","iopub.status.idle":"2022-07-03T15:07:01.097397Z","shell.execute_reply.started":"2022-07-03T15:07:01.087780Z","shell.execute_reply":"2022-07-03T15:07:01.096361Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"show_batch(train_dl)","metadata":{"id":"Vq4NoIZ0ctKs","outputId":"1a34dbab-fd9e-4a44-c986-770ea7746ddf","execution":{"iopub.status.busy":"2022-07-03T15:07:01.099769Z","iopub.execute_input":"2022-07-03T15:07:01.100164Z","iopub.status.idle":"2022-07-03T15:07:04.860761Z","shell.execute_reply.started":"2022-07-03T15:07:01.100128Z","shell.execute_reply":"2022-07-03T15:07:04.859842Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Defining the Model (Convolutional Neural Network)\nIn our previous tutorial, we defined a deep neural network with fully-connected layers using nn.Linear. For this tutorial however, we will use a convolutional neural network, using the nn.Conv2d class from PyTorch.\n\nThe 2D convolution is a fairly simple operation at heart: you start with a kernel, which is simply a small matrix of weights. This kernel “slides” over the 2D input data, performing an elementwise multiplication with the part of the input it is currently on, and then summing up the results into a single output pixel. - Source\n\n\nLet us implement a convolution operation on a 1 channel image with a 3x3 kernel.","metadata":{"id":"6wuSygfmdIsD"}},{"cell_type":"code","source":"def apply_kernel(image, kernel):\n    ri, ci = image.shape       # image dimensions\n    rk, ck = kernel.shape      # kernel dimensions\n    ro, co = ri-rk+1, ci-ck+1  # output dimensions\n    output = torch.zeros([ro, co])\n    for i in range(ro): \n        for j in range(co):\n            output[i,j] = torch.sum(image[i:i+rk,j:j+ck] * kernel)\n    return output","metadata":{"id":"jPSxSaPsctNb","execution":{"iopub.status.busy":"2022-07-03T15:07:04.861965Z","iopub.execute_input":"2022-07-03T15:07:04.862335Z","iopub.status.idle":"2022-07-03T15:07:04.870907Z","shell.execute_reply.started":"2022-07-03T15:07:04.862300Z","shell.execute_reply":"2022-07-03T15:07:04.869680Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"sample_image = torch.tensor([\n    [3, 3, 2, 1, 0], \n    [0, 0, 1, 3, 1], \n    [3, 1, 2, 2, 3], \n    [2, 0, 0, 2, 2], \n    [2, 0, 0, 0, 1]\n], dtype=torch.float32)\n\nsample_kernel = torch.tensor([\n    [0, 1, 2], \n    [2, 2, 0], \n    [0, 1, 2]\n], dtype=torch.float32)\n\napply_kernel(sample_image, sample_kernel)","metadata":{"id":"HLBqRUsVctP8","outputId":"343ea729-8ce1-4fa9-8659-36890a840e8d","execution":{"iopub.status.busy":"2022-07-03T15:07:04.872499Z","iopub.execute_input":"2022-07-03T15:07:04.873588Z","iopub.status.idle":"2022-07-03T15:07:04.888239Z","shell.execute_reply.started":"2022-07-03T15:07:04.873551Z","shell.execute_reply":"2022-07-03T15:07:04.887116Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"For multi-channel images, a different kernel is applied to each channels, and the outputs are added together pixel-wise.\n\nChecking out the following articles to gain a better understanding of convolutions:\n\nIntuitively understanding Convolutions for Deep Learning by Irhum Shafkat\nConvolutions in Depth by Sylvian Gugger (this article implements convolutions from scratch)\nThere are certain advantages offered by convolutional layers when working with image data:\n\nFewer parameters: A small set of parameters (the kernel) is used to calculate outputs of the entire image, so the model has much fewer parameters compared to a fully connected layer.\nSparsity of connections: In each layer, each output element only depends on a small number of input elements, which makes the forward and backward passes more efficient.\nParameter sharing and spatial invariance: The features learned by a kernel in one part of the image can be used to detect similar pattern in a different part of another image.\nWe will also use a max-pooling layers to progressively decrease the height & width of the output tensors from each convolutional layer.","metadata":{"id":"BzdPYPSade_t"}},{"cell_type":"code","source":"","metadata":{"id":"Hqcp6o_PctTe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before we define the entire model, let's look at how a single convolutional layer followed by a max-pooling layer operates on the data.","metadata":{"id":"pA3mLCQfdnVk"}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F","metadata":{"id":"XrGiY1RactV7","execution":{"iopub.status.busy":"2022-07-03T15:07:04.889839Z","iopub.execute_input":"2022-07-03T15:07:04.890355Z","iopub.status.idle":"2022-07-03T15:07:04.896015Z","shell.execute_reply.started":"2022-07-03T15:07:04.890317Z","shell.execute_reply":"2022-07-03T15:07:04.894366Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"simple_model = nn.Sequential(\n    nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1),\n    nn.MaxPool2d(2, 2)\n)","metadata":{"id":"0v4XAhP0do7s","execution":{"iopub.status.busy":"2022-07-03T15:07:04.897871Z","iopub.execute_input":"2022-07-03T15:07:04.898948Z","iopub.status.idle":"2022-07-03T15:07:04.906169Z","shell.execute_reply.started":"2022-07-03T15:07:04.898914Z","shell.execute_reply":"2022-07-03T15:07:04.905206Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = simple_model(images)\n    print('out.shape:', out.shape)\n    break","metadata":{"id":"ZTQGCGAedo_M","outputId":"52e17484-379e-45ac-deb2-f5cc13537f0a","execution":{"iopub.status.busy":"2022-07-03T15:07:04.914853Z","iopub.execute_input":"2022-07-03T15:07:04.915489Z","iopub.status.idle":"2022-07-03T15:07:05.311562Z","shell.execute_reply.started":"2022-07-03T15:07:04.915453Z","shell.execute_reply":"2022-07-03T15:07:05.310464Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"The Conv2d layer transforms a 3-channel image to a 16-channel feature map, and the MaxPool2d layer halves the height and width. The feature map gets smaller as we add more layers, until we are finally left with a small feature map, which can be flattened into a vector. We can then add some fully connected layers at the end to get vector of size 10 for each image.\n\n\nLet's define the model by extending an ImageClassificationBase class which contains helper methods for training & validation","metadata":{"id":"HmQhweQwd6wz"}},{"cell_type":"code","source":"class ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        _, preds = torch.max(out, dim=1)\n        acc=torch.tensor(torch.sum(preds == labels).item() / len(preds))\n        return loss,acc\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n    \n    def test_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'test_loss': loss.detach(), 'test_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def test_epoch_end(self, outputs):\n        batch_losses = [x['test_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['test_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f},train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['train_acc'], result['val_loss'], result['val_acc']))\n        \ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","metadata":{"id":"krNxu_uwdpCE","execution":{"iopub.status.busy":"2022-07-03T15:07:05.314936Z","iopub.execute_input":"2022-07-03T15:07:05.315243Z","iopub.status.idle":"2022-07-03T15:07:05.330550Z","shell.execute_reply.started":"2022-07-03T15:07:05.315215Z","shell.execute_reply":"2022-07-03T15:07:05.329584Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class Cifar10CnnModel(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n\n            nn.Flatten(), \n            nn.Linear(256*4*4, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            #nn.Dropout(inplace=True),\n            nn.Linear(512, 10))\n        \n    def forward(self, xb):\n        return self.network(xb)","metadata":{"id":"AAWBgkbfdpE0","execution":{"iopub.status.busy":"2022-07-03T15:07:05.332148Z","iopub.execute_input":"2022-07-03T15:07:05.333440Z","iopub.status.idle":"2022-07-03T15:07:05.346042Z","shell.execute_reply.started":"2022-07-03T15:07:05.333384Z","shell.execute_reply":"2022-07-03T15:07:05.344964Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = Cifar10CnnModel()\nmodel","metadata":{"id":"DSBjpcjqdpH2","outputId":"e154f9b3-cd81-4a20-8274-2ba767d91cb2","execution":{"iopub.status.busy":"2022-07-03T15:07:05.349169Z","iopub.execute_input":"2022-07-03T15:07:05.349424Z","iopub.status.idle":"2022-07-03T15:07:05.412637Z","shell.execute_reply.started":"2022-07-03T15:07:05.349401Z","shell.execute_reply":"2022-07-03T15:07:05.411756Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","metadata":{"id":"OSH1_ec5dpK_","outputId":"7ef4b448-d748-4cc6-9465-c765789c087f","execution":{"iopub.status.busy":"2022-07-03T15:07:05.415835Z","iopub.execute_input":"2022-07-03T15:07:05.416084Z","iopub.status.idle":"2022-07-03T15:07:07.192603Z","shell.execute_reply.started":"2022-07-03T15:07:05.416060Z","shell.execute_reply":"2022-07-03T15:07:07.191509Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"To seamlessly use a GPU, if one is available, we define a couple of helper functions (get_default_device & to_device) and a helper class DeviceDataLoader to move our model & data to the GPU as required. These are described in more detail in the previous tutorial.","metadata":{"id":"JEo4v7M8edgV"}},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"id":"qCg5sNhBdpPl","execution":{"iopub.status.busy":"2022-07-03T15:07:07.194814Z","iopub.execute_input":"2022-07-03T15:07:07.195704Z","iopub.status.idle":"2022-07-03T15:07:07.208226Z","shell.execute_reply.started":"2022-07-03T15:07:07.195652Z","shell.execute_reply":"2022-07-03T15:07:07.206851Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"id":"TwWAFtHReOal","outputId":"3f77635d-c40b-4237-e43f-239a160f00c5","execution":{"iopub.status.busy":"2022-07-03T15:07:07.210223Z","iopub.execute_input":"2022-07-03T15:07:07.210851Z","iopub.status.idle":"2022-07-03T15:07:07.228241Z","shell.execute_reply.started":"2022-07-03T15:07:07.210812Z","shell.execute_reply":"2022-07-03T15:07:07.226719Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nto_device(model, device);","metadata":{"id":"zd7d_xiseOdu","execution":{"iopub.status.busy":"2022-07-03T15:07:07.230633Z","iopub.execute_input":"2022-07-03T15:07:07.231336Z","iopub.status.idle":"2022-07-03T15:07:07.256516Z","shell.execute_reply.started":"2022-07-03T15:07:07.231299Z","shell.execute_reply":"2022-07-03T15:07:07.255076Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Training the Model\nWe'll define two functions: fit and evaluate to train the model using gradient descent and evaluate its performance on the validation set. For a detailed walkthrough of these functions, check out the previous tutorial.","metadata":{"id":"q1OtbNzyerFU"}},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef evaluate_test(model, test_loader):\n    model.eval()\n    outputs = [model.test_step(batch) for batch in test_loader]\n    return model.test_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        train_accuracy = []\n        for batch in train_loader:\n            loss,acc = model.training_step(batch)\n            train_losses.append(loss)\n            train_accuracy.append(acc)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['train_acc'] = torch.stack(train_accuracy).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history\ndef fit_dynamic(epochs, lr, model, opt_func=torch.optim.Adam):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        #dynamically build training and validation datasets\n        torch.manual_seed( epoch)\n        train_ds, val_ds = random_split(dataset, [train_size, val_size])\n        train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n        val_dl = DataLoader(val_ds, batch_size, num_workers=2, pin_memory=True)\n        train_dl = DeviceDataLoader(train_dl, device)\n        val_dl = DeviceDataLoader(val_dl, device)\n        \n        # Training Phase \n        model.train()\n        train_losses = []\n        train_accuracy = []\n        for batch in train_dl:\n            loss,acc = model.training_step(batch)\n            train_losses.append(loss)\n            train_accuracy.append(acc)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_dl)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['train_acc'] = torch.stack(train_accuracy).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"id":"FgyZRTjbeOgl","execution":{"iopub.status.busy":"2022-07-03T15:07:07.258551Z","iopub.execute_input":"2022-07-03T15:07:07.259155Z","iopub.status.idle":"2022-07-03T15:07:07.290093Z","shell.execute_reply.started":"2022-07-03T15:07:07.259119Z","shell.execute_reply":"2022-07-03T15:07:07.288693Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model = to_device(Cifar10CnnModel(), device)","metadata":{"id":"LNlJJNXyeOjl","execution":{"iopub.status.busy":"2022-07-03T15:07:07.295100Z","iopub.execute_input":"2022-07-03T15:07:07.295944Z","iopub.status.idle":"2022-07-03T15:07:07.394384Z","shell.execute_reply.started":"2022-07-03T15:07:07.295908Z","shell.execute_reply":"2022-07-03T15:07:07.392325Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"evaluate(model, val_dl)","metadata":{"id":"PRbX5dWBeOmN","outputId":"5b3c8067-21b3-472c-a1c7-734680066d11","execution":{"iopub.status.busy":"2022-07-03T15:07:07.402246Z","iopub.execute_input":"2022-07-03T15:07:07.406226Z","iopub.status.idle":"2022-07-03T15:07:15.081649Z","shell.execute_reply.started":"2022-07-03T15:07:07.406187Z","shell.execute_reply":"2022-07-03T15:07:15.080564Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"num_epochs = 30\nopt_func = torch.optim.Adam\nlr = 0.001","metadata":{"id":"qAPvLsvefA-1","execution":{"iopub.status.busy":"2022-07-03T15:07:15.083999Z","iopub.execute_input":"2022-07-03T15:07:15.084598Z","iopub.status.idle":"2022-07-03T15:07:15.089850Z","shell.execute_reply.started":"2022-07-03T15:07:15.084559Z","shell.execute_reply":"2022-07-03T15:07:15.088890Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)\nhistory = fit_dynamic(num_epochs, lr, model, opt_func)","metadata":{"id":"SmHsdd-afBBs","outputId":"211bdfe2-a37b-403c-faaa-bb36a8fcfe87","execution":{"iopub.status.busy":"2022-07-03T15:07:15.091441Z","iopub.execute_input":"2022-07-03T15:07:15.092054Z","iopub.status.idle":"2022-07-03T15:14:55.420792Z","shell.execute_reply.started":"2022-07-03T15:07:15.092017Z","shell.execute_reply":"2022-07-03T15:14:55.419596Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\nplot_accuracies(history)","metadata":{"id":"pPyAjDEMfBEb","execution":{"iopub.status.busy":"2022-07-03T15:14:55.426207Z","iopub.execute_input":"2022-07-03T15:14:55.428991Z","iopub.status.idle":"2022-07-03T15:14:55.654862Z","shell.execute_reply.started":"2022-07-03T15:14:55.428949Z","shell.execute_reply":"2022-07-03T15:14:55.653882Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\nplot_losses(history)","metadata":{"id":"A01pRQSNfBJc","execution":{"iopub.status.busy":"2022-07-03T15:14:55.659437Z","iopub.execute_input":"2022-07-03T15:14:55.661840Z","iopub.status.idle":"2022-07-03T15:14:55.881504Z","shell.execute_reply.started":"2022-07-03T15:14:55.661776Z","shell.execute_reply":"2022-07-03T15:14:55.880556Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Testing with individual images\nWhile we have been tracking the overall accuracy of a model so far, it's also a good idea to look at model's results on some sample images. Let's test out our model with some images from the predefined test dataset of 10000 images. We begin by creating a test dataset using the ImageFolder class.","metadata":{"id":"q_CoiFbCfite"}},{"cell_type":"code","source":"test_dataset = ImageFolder(data_dir+'/test', transform=ToTensor())","metadata":{"id":"WAYBNwpHfBMl","execution":{"iopub.status.busy":"2022-07-03T15:14:55.882840Z","iopub.execute_input":"2022-07-03T15:14:55.883862Z","iopub.status.idle":"2022-07-03T15:14:55.931033Z","shell.execute_reply.started":"2022-07-03T15:14:55.883819Z","shell.execute_reply":"2022-07-03T15:14:55.930164Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"print(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T15:14:55.932212Z","iopub.execute_input":"2022-07-03T15:14:55.932549Z","iopub.status.idle":"2022-07-03T15:14:55.938660Z","shell.execute_reply.started":"2022-07-03T15:14:55.932511Z","shell.execute_reply":"2022-07-03T15:14:55.937655Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def predict_image(img, model):\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n    return dataset.classes[preds[0].item()]","metadata":{"id":"FFBUvoRLfBPF","execution":{"iopub.status.busy":"2022-07-03T15:14:55.940239Z","iopub.execute_input":"2022-07-03T15:14:55.940984Z","iopub.status.idle":"2022-07-03T15:14:55.947463Z","shell.execute_reply.started":"2022-07-03T15:14:55.940950Z","shell.execute_reply":"2022-07-03T15:14:55.946462Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"img, label = test_dataset[0]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))","metadata":{"id":"aVXC58c8fBSG","execution":{"iopub.status.busy":"2022-07-03T15:14:55.949124Z","iopub.execute_input":"2022-07-03T15:14:55.949903Z","iopub.status.idle":"2022-07-03T15:14:56.129330Z","shell.execute_reply.started":"2022-07-03T15:14:55.949867Z","shell.execute_reply":"2022-07-03T15:14:56.128237Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"img, label = test_dataset[1002]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))","metadata":{"id":"KX-Lr1O1fBVw","execution":{"iopub.status.busy":"2022-07-03T15:14:56.131189Z","iopub.execute_input":"2022-07-03T15:14:56.131589Z","iopub.status.idle":"2022-07-03T15:14:56.302630Z","shell.execute_reply.started":"2022-07-03T15:14:56.131549Z","shell.execute_reply":"2022-07-03T15:14:56.301649Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"img, label = test_dataset[6153]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))","metadata":{"id":"zM0bt7fifzaO","execution":{"iopub.status.busy":"2022-07-03T15:14:56.303966Z","iopub.execute_input":"2022-07-03T15:14:56.304724Z","iopub.status.idle":"2022-07-03T15:14:56.478550Z","shell.execute_reply.started":"2022-07-03T15:14:56.304684Z","shell.execute_reply":"2022-07-03T15:14:56.477600Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size), device)\nresult = evaluate_test(model, test_loader)\nresult","metadata":{"id":"SZCEQNCsfzdU","execution":{"iopub.status.busy":"2022-07-03T15:14:56.480231Z","iopub.execute_input":"2022-07-03T15:14:56.480594Z","iopub.status.idle":"2022-07-03T15:15:00.168469Z","shell.execute_reply.started":"2022-07-03T15:14:56.480558Z","shell.execute_reply":"2022-07-03T15:15:00.167518Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'cifar10-cnn.pth')","metadata":{"id":"leZ8aP-zfziv","execution":{"iopub.status.busy":"2022-07-03T15:15:00.170006Z","iopub.execute_input":"2022-07-03T15:15:00.170362Z","iopub.status.idle":"2022-07-03T15:15:00.234857Z","shell.execute_reply.started":"2022-07-03T15:15:00.170316Z","shell.execute_reply":"2022-07-03T15:15:00.233840Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"model2 = to_device(Cifar10CnnModel(), device)","metadata":{"id":"DqEZJjbjf89t","execution":{"iopub.status.busy":"2022-07-03T15:15:00.236416Z","iopub.execute_input":"2022-07-03T15:15:00.236930Z","iopub.status.idle":"2022-07-03T15:15:00.289519Z","shell.execute_reply.started":"2022-07-03T15:15:00.236890Z","shell.execute_reply":"2022-07-03T15:15:00.288620Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"model2.load_state_dict(torch.load('cifar10-cnn.pth'))","metadata":{"id":"VRchwYKYf9A2","execution":{"iopub.status.busy":"2022-07-03T15:15:00.290841Z","iopub.execute_input":"2022-07-03T15:15:00.291558Z","iopub.status.idle":"2022-07-03T15:15:00.316485Z","shell.execute_reply.started":"2022-07-03T15:15:00.291512Z","shell.execute_reply":"2022-07-03T15:15:00.315589Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"evaluate_test(model2, test_loader)","metadata":{"id":"k0xzR4dEf9Dg","execution":{"iopub.status.busy":"2022-07-03T15:15:00.317789Z","iopub.execute_input":"2022-07-03T15:15:00.318193Z","iopub.status.idle":"2022-07-03T15:15:03.939553Z","shell.execute_reply.started":"2022-07-03T15:15:00.318155Z","shell.execute_reply":"2022-07-03T15:15:03.938523Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"Summary and Further Reading/Exercises\nWe've covered a lot of ground in this tutorial. Here's quick recap of the topics:\n\nIntroduction to the CIFAR10 dataset for image classification\nDownloading, extracing and loading an image dataset using torchvision\nShow random batches of images in a grid using torchvision.utils.make_grid\nCreating a convolutional neural network using with nn.Conv2d and nn.MaxPool2d layers\nCapturing dataset information, metrics and hyperparameters using the jovian library\nTraining a convolutional neural network and visualizing the losses and errors\nUnderstanding overfitting and the strategies for avoiding it (more on this later)\nGenerating predictions on single images from the test set","metadata":{"id":"J2t9zXxFgPo1"}},{"cell_type":"code","source":"","metadata":{"id":"YBwyvkacf9Ie"},"execution_count":null,"outputs":[]}]}