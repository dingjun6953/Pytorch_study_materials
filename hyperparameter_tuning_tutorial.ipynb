{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tvjawo9qlhH6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray"
      ],
      "metadata": {
        "id": "J5FyEszxloVm",
        "outputId": "f28a3a67-b822-405c-bea2-449e0ddfee7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ray\n",
            "  Downloading ray-1.13.0-cp37-cp37m-manylinux2014_x86_64.whl (54.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.5 MB 156 kB/s \n",
            "\u001b[?25hCollecting virtualenv\n",
            "  Downloading virtualenv-20.15.1-py2.py3-none-any.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 36.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.4.0)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Collecting aiosignal\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Collecting frozenlist\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 75.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.1.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 68.0 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: platformdirs, frozenlist, distlib, virtualenv, grpcio, aiosignal, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.3\n",
            "    Uninstalling grpcio-1.46.3:\n",
            "      Successfully uninstalled grpcio-1.46.3\n",
            "Successfully installed aiosignal-1.2.0 distlib-0.3.4 frozenlist-1.3.0 grpcio-1.43.0 platformdirs-2.5.2 ray-1.13.0 virtualenv-20.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuX3BxCilhH9"
      },
      "source": [
        "\n",
        "Hyperparameter tuning with Ray Tune\n",
        "===================================\n",
        "\n",
        "Hyperparameter tuning can make the difference between an average model and a highly\n",
        "accurate one. Often simple things like choosing a different learning rate or changing\n",
        "a network layer size can have a dramatic impact on your model performance.\n",
        "\n",
        "Fortunately, there are tools that help with finding the best combination of parameters.\n",
        "`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for\n",
        "distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search\n",
        "algorithms, integrates with TensorBoard and other analysis libraries, and natively\n",
        "supports distributed training through `Ray's distributed machine learning engine\n",
        "<https://ray.io/>`_.\n",
        "\n",
        "In this tutorial, we will show you how to integrate Ray Tune into your PyTorch\n",
        "training workflow. We will extend `this tutorial from the PyTorch documentation\n",
        "<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training\n",
        "a CIFAR10 image classifier.\n",
        "\n",
        "As you will see, we only need to add some slight modifications. In particular, we\n",
        "need to\n",
        "\n",
        "1. wrap data loading and training in functions,\n",
        "2. make some network parameters configurable,\n",
        "3. add checkpointing (optional),\n",
        "4. and define the search space for the model tuning\n",
        "\n",
        "|\n",
        "\n",
        "To run this tutorial, please make sure the following packages are\n",
        "installed:\n",
        "\n",
        "-  ``ray[tune]``: Distributed hyperparameter tuning library\n",
        "-  ``torchvision``: For the data transformers\n",
        "\n",
        "Setup / Imports\n",
        "---------------\n",
        "Let's start with the imports:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s-X0iiOllhH_"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I94pDJ8ElhIA"
      },
      "source": [
        "Most of the imports are needed for building the PyTorch model. Only the last three\n",
        "imports are for Ray Tune.\n",
        "\n",
        "Data loaders\n",
        "------------\n",
        "We wrap the data loaders in their own function and pass a global data directory.\n",
        "This way we can share a data directory between different trials.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bAjMW6cHlhIA"
      },
      "outputs": [],
      "source": [
        "def load_data(data_dir=\"./data\"):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=True, download=True, transform=transform)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    return trainset, testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8nuOFwjlhIB"
      },
      "source": [
        "Configurable neural network\n",
        "---------------------------\n",
        "We can only tune those parameters that are configurable. In this example, we can specify\n",
        "the layer sizes of the fully connected layers:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yHMV8Ha1lhIB"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, l1=120, l2=84):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
        "        self.fc2 = nn.Linear(l1, l2)\n",
        "        self.fc3 = nn.Linear(l2, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h2zyCEUlhIC"
      },
      "source": [
        "The train function\n",
        "------------------\n",
        "Now it gets interesting, because we introduce some changes to the example `from the PyTorch\n",
        "documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.\n",
        "\n",
        "We wrap the training script in a function ``train_cifar(config, checkpoint_dir=None, data_dir=None)``.\n",
        "As you can guess, the ``config`` parameter will receive the hyperparameters we would like to\n",
        "train with. The ``checkpoint_dir`` parameter is used to restore checkpoints. The ``data_dir`` specifies\n",
        "the directory where we load and store the data, so multiple runs can share the same data source.\n",
        "\n",
        ".. code-block:: python\n",
        "\n",
        "    net = Net(config[\"l1\"], config[\"l2\"])\n",
        "\n",
        "    if checkpoint_dir:\n",
        "        model_state, optimizer_state = torch.load(\n",
        "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
        "        net.load_state_dict(model_state)\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "The learning rate of the optimizer is made configurable, too:\n",
        "\n",
        ".. code-block:: python\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
        "\n",
        "We also split the training data into a training and validation subset. We thus train on\n",
        "80% of the data and calculate the validation loss on the remaining 20%. The batch sizes\n",
        "with which we iterate through the training and test sets are configurable as well.\n",
        "\n",
        "Adding (multi) GPU support with DataParallel\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Image classification benefits largely from GPUs. Luckily, we can continue to use\n",
        "PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``\n",
        "to support data parallel training on multiple GPUs:\n",
        "\n",
        ".. code-block:: python\n",
        "\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            net = nn.DataParallel(net)\n",
        "    net.to(device)\n",
        "\n",
        "By using a ``device`` variable we make sure that training also works when we have\n",
        "no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,\n",
        "like this:\n",
        "\n",
        ".. code-block:: python\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray\n",
        "also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_\n",
        "so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back\n",
        "to that later.\n",
        "\n",
        "Communicating with Ray Tune\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "The most interesting part is the communication with Ray Tune:\n",
        "\n",
        ".. code-block:: python\n",
        "\n",
        "    with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
        "        path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "        torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
        "\n",
        "    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
        "\n",
        "Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,\n",
        "we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics\n",
        "to decide which hyperparameter configuration lead to the best results. These metrics\n",
        "can also be used to stop bad performing trials early in order to avoid wasting\n",
        "resources on those trials.\n",
        "\n",
        "The checkpoint saving is optional, however, it is necessary if we wanted to use advanced\n",
        "schedulers like\n",
        "`Population Based Training <https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html>`_.\n",
        "Also, by saving the checkpoint we can later load the trained models and validate them\n",
        "on a test set.\n",
        "\n",
        "Full training function\n",
        "~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "The full code example looks like this:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UJRIjZyWlhID"
      },
      "outputs": [],
      "source": [
        "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n",
        "    net = Net(config[\"l1\"], config[\"l2\"])\n",
        "\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            net = nn.DataParallel(net)\n",
        "    net.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
        "\n",
        "    if checkpoint_dir:\n",
        "        model_state, optimizer_state = torch.load(\n",
        "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
        "        net.load_state_dict(model_state)\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "    trainset, testset = load_data(data_dir)\n",
        "\n",
        "    test_abs = int(len(trainset) * 0.8)\n",
        "    train_subset, val_subset = random_split(\n",
        "        trainset, [test_abs, len(trainset) - test_abs])\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=int(config[\"batch_size\"]),\n",
        "        shuffle=True,\n",
        "        num_workers=8)\n",
        "    valloader = torch.utils.data.DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=int(config[\"batch_size\"]),\n",
        "        shuffle=True,\n",
        "        num_workers=8)\n",
        "\n",
        "    for epoch in range(10):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        epoch_steps = 0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            epoch_steps += 1\n",
        "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
        "                                                running_loss / epoch_steps))\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Validation loss\n",
        "        val_loss = 0.0\n",
        "        val_steps = 0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for i, data in enumerate(valloader, 0):\n",
        "            with torch.no_grad():\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = net(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.cpu().numpy()\n",
        "                val_steps += 1\n",
        "\n",
        "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
        "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
        "\n",
        "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
        "    print(\"Finished Training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-oXKF5llhID"
      },
      "source": [
        "As you can see, most of the code is adapted directly from the original example.\n",
        "\n",
        "Test set accuracy\n",
        "-----------------\n",
        "Commonly the performance of a machine learning model is tested on a hold-out test\n",
        "set with data that has not been used for training the model. We also wrap this in a\n",
        "function:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WMGr_LiWlhIE"
      },
      "outputs": [],
      "source": [
        "def test_accuracy(net, device=\"cpu\"):\n",
        "    trainset, testset = load_data()\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuSQq-G5lhIE"
      },
      "source": [
        "The function also expects a ``device`` parameter, so we can do the\n",
        "test set validation on a GPU.\n",
        "\n",
        "Configuring the search space\n",
        "----------------------------\n",
        "Lastly, we need to define Ray Tune's search space. Here is an example:\n",
        "\n",
        ".. code-block:: python\n",
        "\n",
        "    config = {\n",
        "        \"l1\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
        "        \"l2\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
        "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "        \"batch_size\": tune.choice([2, 4, 8, 16])\n",
        "    }\n",
        "\n",
        "The ``tune.sample_from()`` function makes it possible to define your own sample\n",
        "methods to obtain hyperparameters. In this example, the ``l1`` and ``l2`` parameters\n",
        "should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.\n",
        "The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,\n",
        "the batch size is a choice between 2, 4, 8, and 16.\n",
        "\n",
        "At each trial, Ray Tune will now randomly sample a combination of parameters from these\n",
        "search spaces. It will then train a number of models in parallel and find the best\n",
        "performing one among these. We also use the ``ASHAScheduler`` which will terminate bad\n",
        "performing trials early.\n",
        "\n",
        "We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant\n",
        "``data_dir`` parameter. We can also tell Ray Tune what resources should be\n",
        "available for each trial:\n",
        "\n",
        ".. code-block:: python\n",
        "\n",
        "    gpus_per_trial = 2\n",
        "    # ...\n",
        "    result = tune.run(\n",
        "        partial(train_cifar, data_dir=data_dir),\n",
        "        resources_per_trial={\"cpu\": 8, \"gpu\": gpus_per_trial},\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter,\n",
        "        checkpoint_at_end=True)\n",
        "\n",
        "You can specify the number of CPUs, which are then available e.g.\n",
        "to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected\n",
        "number of GPUs are made visible to PyTorch in each trial. Trials do not have access to\n",
        "GPUs that haven't been requested for them - so you don't have to care about two trials\n",
        "using the same set of resources.\n",
        "\n",
        "Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is\n",
        "completely valid. The trials will then share GPUs among each other.\n",
        "You just have to make sure that the models still fit in the GPU memory.\n",
        "\n",
        "After training the models, we will find the best performing one and load the trained\n",
        "network from the checkpoint file. We then obtain the test set accuracy and report\n",
        "everything by printing.\n",
        "\n",
        "The full main function looks like this:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MKULs2HMlhIF",
        "outputId": "52e91298-cbdb-46e6-efbd-f59248719777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0d0271b98b0e435ba372875bfaab4f1b",
            "8bd7a55073354c7b80973b1f9482cc4f",
            "c3234dabe956409ebb66139974ba4a30",
            "a0bcca8600de47a396327e32371c8be2",
            "6c46fa64ca7b4a5780ecacec061f03d7",
            "241f01ef828c455ab4cb40b34b4ec7a3",
            "c037dd43599a42749cea28bfb02fd7fa",
            "201cfbff90a348b9b6e2cc813fa0c7a7",
            "429f310f63d94692a1f247ce33403cde",
            "543888956c3c4071bff62c2c0df0179e",
            "f5a91ee4187d4d259f3696950c05c034"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d0271b98b0e435ba372875bfaab4f1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/cifar-10-python.tar.gz to /content/data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-29 22:39:24,301\tINFO logger.py:630 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
            "2022-06-29 22:39:24,303\tWARNING callback.py:106 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
            "2022-06-29 22:39:24,317\tWARNING tune.py:669 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2022-06-29 22:39:24 (running for 00:00:00.37)\n",
            "Memory usage on this node: 1.4/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+----------------+--------------+------+------+-------------+\n",
            "| Trial name              | status   | loc            |   batch_size |   l1 |   l2 |          lr |\n",
            "|-------------------------+----------+----------------+--------------+------+------+-------------|\n",
            "| train_cifar_534cc_00000 | RUNNING  | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 |\n",
            "| train_cifar_534cc_00001 | PENDING  |                |           16 |    8 |  256 | 0.000516031 |\n",
            "| train_cifar_534cc_00002 | PENDING  |                |           16 |    8 |   16 | 0.00961721  |\n",
            "| train_cifar_534cc_00003 | PENDING  |                |            2 |  256 |    4 | 0.0782832   |\n",
            "| train_cifar_534cc_00004 | PENDING  |                |            2 |   16 |  128 | 0.0638543   |\n",
            "| train_cifar_534cc_00005 | PENDING  |                |           16 |    8 |    8 | 0.0528172   |\n",
            "| train_cifar_534cc_00006 | PENDING  |                |            8 |   16 |   64 | 0.000161347 |\n",
            "| train_cifar_534cc_00007 | PENDING  |                |            8 |  256 |   16 | 0.00492784  |\n",
            "| train_cifar_534cc_00008 | PENDING  |                |            4 |   16 |   64 | 0.0060132   |\n",
            "| train_cifar_534cc_00009 | PENDING  |                |           16 |    8 |  256 | 0.0431248   |\n",
            "+-------------------------+----------+----------------+--------------+------+------+-------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m   cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.31822 |     0.5182 |                    6 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:45:51 (running for 00:06:27.46)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.31822 |     0.5182 |                    6 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00001:\n",
            "  accuracy: 0.5288\n",
            "  date: 2022-06-29_22-45-53\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 7\n",
            "  loss: 1.303913704776764\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 152.5202977657318\n",
            "  time_this_iter_s: 21.43019127845764\n",
            "  time_total_s: 152.5202977657318\n",
            "  timestamp: 1656542753\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 7\n",
            "  trial_id: 534cc_00001\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:45:58 (running for 00:06:33.79)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.30391 |     0.5288 |                    7 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:46:03 (running for 00:06:38.85)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.30391 |     0.5288 |                    7 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [8,  2000] loss: 1.270\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:46:08 (running for 00:06:43.88)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.30391 |     0.5288 |                    7 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:46:13 (running for 00:06:48.91)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.30391 |     0.5288 |                    7 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00001:\n",
            "  accuracy: 0.5396\n",
            "  date: 2022-06-29_22-46-14\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 8\n",
            "  loss: 1.2700892845153808\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 173.86610174179077\n",
            "  time_this_iter_s: 21.34580397605896\n",
            "  time_total_s: 173.86610174179077\n",
            "  timestamp: 1656542774\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 8\n",
            "  trial_id: 534cc_00001\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:46:19 (running for 00:06:55.14)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.27009 |     0.5396 |                    8 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:46:24 (running for 00:07:00.22)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.27009 |     0.5396 |                    8 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [9,  2000] loss: 1.237\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:46:29 (running for 00:07:05.22)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.27009 |     0.5396 |                    8 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:46:34 (running for 00:07:10.24)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.27009 |     0.5396 |                    8 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00001:\n",
            "  accuracy: 0.5543\n",
            "  date: 2022-06-29_22-46-35\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 9\n",
            "  loss: 1.2377436882972717\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 195.31452679634094\n",
            "  time_this_iter_s: 21.44842505455017\n",
            "  time_total_s: 195.31452679634094\n",
            "  timestamp: 1656542795\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 9\n",
            "  trial_id: 534cc_00001\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:46:40 (running for 00:07:16.59)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.23774 |     0.5543 |                    9 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:46:45 (running for 00:07:21.61)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.23774 |     0.5543 |                    9 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [10,  2000] loss: 1.199\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:46:50 (running for 00:07:26.65)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.23774 |     0.5543 |                    9 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:46:55 (running for 00:07:31.66)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00001 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.23774 |     0.5543 |                    9 |\n",
            "| train_cifar_534cc_00002 | PENDING    |                |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00001:\n",
            "  accuracy: 0.5582\n",
            "  date: 2022-06-29_22-46-57\n",
            "  done: true\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 10\n",
            "  loss: 1.2284743344306945\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 216.44612336158752\n",
            "  time_this_iter_s: 21.131596565246582\n",
            "  time_total_s: 216.44612336158752\n",
            "  timestamp: 1656542817\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 10\n",
            "  trial_id: 534cc_00001\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:47:02 (running for 00:07:37.74)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:47:07 (running for 00:07:42.77)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:47:12 (running for 00:07:47.79)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  2000] loss: 1.835\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:47:17 (running for 00:07:52.81)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  |         |            |                      |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00002:\n",
            "  accuracy: 0.3859\n",
            "  date: 2022-06-29_22-47-21\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.6732194101333617\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 24.410133123397827\n",
            "  time_this_iter_s: 24.410133123397827\n",
            "  time_total_s: 24.410133123397827\n",
            "  timestamp: 1656542841\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 534cc_00002\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:47:26 (running for 00:08:02.16)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.67322 |     0.3859 |                    1 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:47:31 (running for 00:08:07.18)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.67322 |     0.3859 |                    1 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [2,  2000] loss: 1.554\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:47:36 (running for 00:08:12.20)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.67322 |     0.3859 |                    1 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:47:41 (running for 00:08:17.24)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.815007333755493 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.67322 |     0.3859 |                    1 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00002:\n",
            "  accuracy: 0.4564\n",
            "  date: 2022-06-29_22-47-42\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 2\n",
            "  loss: 1.499562741470337\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 45.59006214141846\n",
            "  time_this_iter_s: 21.17992901802063\n",
            "  time_total_s: 45.59006214141846\n",
            "  timestamp: 1656542862\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: 534cc_00002\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:47:47 (running for 00:08:23.34)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.49956 |     0.4564 |                    2 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:47:52 (running for 00:08:28.38)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.49956 |     0.4564 |                    2 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [3,  2000] loss: 1.491\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:47:57 (running for 00:08:33.40)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.49956 |     0.4564 |                    2 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:48:02 (running for 00:08:38.45)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.49956 |     0.4564 |                    2 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00002:\n",
            "  accuracy: 0.4422\n",
            "  date: 2022-06-29_22-48-03\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 3\n",
            "  loss: 1.533168155670166\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 66.43570017814636\n",
            "  time_this_iter_s: 20.845638036727905\n",
            "  time_total_s: 66.43570017814636\n",
            "  timestamp: 1656542883\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 3\n",
            "  trial_id: 534cc_00002\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:48:08 (running for 00:08:44.18)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.53317 |     0.4422 |                    3 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:48:13 (running for 00:08:49.20)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.53317 |     0.4422 |                    3 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [4,  2000] loss: 1.447\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:48:18 (running for 00:08:54.22)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.53317 |     0.4422 |                    3 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:48:23 (running for 00:08:59.23)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.5248944112300873 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.53317 |     0.4422 |                    3 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00002:\n",
            "  accuracy: 0.486\n",
            "  date: 2022-06-29_22-48-24\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 4\n",
            "  loss: 1.4394416034698487\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 87.5907666683197\n",
            "  time_this_iter_s: 21.15506649017334\n",
            "  time_total_s: 87.5907666683197\n",
            "  timestamp: 1656542904\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 4\n",
            "  trial_id: 534cc_00002\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:48:29 (running for 00:09:05.34)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.43944 |     0.486  |                    4 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:48:34 (running for 00:09:10.37)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.43944 |     0.486  |                    4 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [5,  2000] loss: 1.429\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:48:39 (running for 00:09:15.39)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.43944 |     0.486  |                    4 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:48:44 (running for 00:09:20.40)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.43944 |     0.486  |                    4 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00002:\n",
            "  accuracy: 0.4858\n",
            "  date: 2022-06-29_22-48-45\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 5\n",
            "  loss: 1.415348542690277\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 108.57116866111755\n",
            "  time_this_iter_s: 20.98040199279785\n",
            "  time_total_s: 108.57116866111755\n",
            "  timestamp: 1656542925\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 5\n",
            "  trial_id: 534cc_00002\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:48:50 (running for 00:09:26.32)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.41535 |     0.4858 |                    5 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:48:55 (running for 00:09:31.34)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.41535 |     0.4858 |                    5 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [6,  2000] loss: 1.422\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:49:00 (running for 00:09:36.35)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.41535 |     0.4858 |                    5 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:49:05 (running for 00:09:41.37)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.41535 |     0.4858 |                    5 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00002:\n",
            "  accuracy: 0.4993\n",
            "  date: 2022-06-29_22-49-06\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 6\n",
            "  loss: 1.422894884109497\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 129.62363958358765\n",
            "  time_this_iter_s: 21.052470922470093\n",
            "  time_total_s: 129.62363958358765\n",
            "  timestamp: 1656542946\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 6\n",
            "  trial_id: 534cc_00002\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:49:11 (running for 00:09:47.37)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.42289 |     0.4993 |                    6 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:49:16 (running for 00:09:52.39)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.42289 |     0.4993 |                    6 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [7,  2000] loss: 1.394\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:49:21 (running for 00:09:57.41)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.42289 |     0.4993 |                    6 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:49:26 (running for 00:10:02.48)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.42289 |     0.4993 |                    6 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00002:\n",
            "  accuracy: 0.5022\n",
            "  date: 2022-06-29_22-49-27\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 7\n",
            "  loss: 1.4155979693412781\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 150.59501695632935\n",
            "  time_this_iter_s: 20.9713773727417\n",
            "  time_total_s: 150.59501695632935\n",
            "  timestamp: 1656542967\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 7\n",
            "  trial_id: 534cc_00002\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:49:32 (running for 00:10:08.34)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.4156  |     0.5022 |                    7 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:49:37 (running for 00:10:13.39)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.4156  |     0.5022 |                    7 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [8,  2000] loss: 1.384\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:49:42 (running for 00:10:18.39)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.4156  |     0.5022 |                    7 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:49:47 (running for 00:10:23.41)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -1.322703081035614 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00002 | RUNNING    | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.4156  |     0.5022 |                    7 |\n",
            "| train_cifar_534cc_00003 | PENDING    |                |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00002:\n",
            "  accuracy: 0.4804\n",
            "  date: 2022-06-29_22-49-48\n",
            "  done: true\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 8\n",
            "  loss: 1.4522668749809264\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 171.28336334228516\n",
            "  time_this_iter_s: 20.68834638595581\n",
            "  time_total_s: 171.28336334228516\n",
            "  timestamp: 1656542988\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 8\n",
            "  trial_id: 534cc_00002\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:49:53 (running for 00:10:29.05)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:49:58 (running for 00:10:34.07)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  2000] loss: 2.396\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:50:03 (running for 00:10:39.08)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:50:08 (running for 00:10:44.09)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  4000] loss: 1.196\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:50:13 (running for 00:10:49.10)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:50:18 (running for 00:10:54.10)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  6000] loss: 0.796\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:50:23 (running for 00:10:59.12)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:50:28 (running for 00:11:04.13)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  8000] loss: 0.598\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:50:33 (running for 00:11:09.14)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 10000] loss: 0.479\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:50:38 (running for 00:11:14.16)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:50:43 (running for 00:11:19.17)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 12000] loss: 0.400\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:50:48 (running for 00:11:24.19)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:50:53 (running for 00:11:29.20)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 14000] loss: 0.342\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:50:58 (running for 00:11:34.22)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:51:03 (running for 00:11:39.24)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:51:08 (running for 00:11:44.26)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 16000] loss: 0.299\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:51:13 (running for 00:11:49.27)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:51:18 (running for 00:11:54.29)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 18000] loss: 0.266\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:51:23 (running for 00:11:59.30)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:51:28 (running for 00:12:04.31)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 20000] loss: 0.238\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:51:33 (running for 00:12:09.32)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:51:38 (running for 00:12:14.34)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -1.9658488422393798\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00003 | RUNNING    | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   |         |            |                      |\n",
            "| train_cifar_534cc_00004 | PENDING    |                |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00003:\n",
            "  accuracy: 0.1006\n",
            "  date: 2022-06-29_22-51-40\n",
            "  done: true\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 1\n",
            "  loss: 2.4368717860460283\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 112.45602202415466\n",
            "  time_this_iter_s: 112.45602202415466\n",
            "  time_total_s: 112.45602202415466\n",
            "  timestamp: 1656543100\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 534cc_00003\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:51:45 (running for 00:12:21.53)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  2000] loss: 2.379\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:51:50 (running for 00:12:26.54)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:51:55 (running for 00:12:31.56)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  4000] loss: 1.190\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:52:00 (running for 00:12:36.57)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  6000] loss: 0.793\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:52:05 (running for 00:12:41.58)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  8000] loss: 0.593\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:52:10 (running for 00:12:46.60)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:52:15 (running for 00:12:51.61)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 10000] loss: 0.474\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:52:20 (running for 00:12:56.62)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 12000] loss: 0.396\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:52:25 (running for 00:13:01.63)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:52:30 (running for 00:13:06.64)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 14000] loss: 0.340\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:52:35 (running for 00:13:11.65)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 16000] loss: 0.298\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:52:40 (running for 00:13:16.67)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:52:45 (running for 00:13:21.68)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 18000] loss: 0.264\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:52:51 (running for 00:13:26.69)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 20000] loss: 0.238\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:52:56 (running for 00:13:31.70)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:53:01 (running for 00:13:36.71)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.101106346130371\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00004 | RUNNING    | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   |         |            |                      |\n",
            "| train_cifar_534cc_00005 | PENDING    |                |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00004:\n",
            "  accuracy: 0.0965\n",
            "  date: 2022-06-29_22-53-05\n",
            "  done: true\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 1\n",
            "  loss: 2.4126911224365233\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 84.20259404182434\n",
            "  time_this_iter_s: 84.20259404182434\n",
            "  time_total_s: 84.20259404182434\n",
            "  timestamp: 1656543185\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 534cc_00004\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:53:10 (running for 00:13:45.76)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00005 | RUNNING    | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:53:15 (running for 00:13:50.81)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00005 | RUNNING    | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:53:20 (running for 00:13:55.83)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00005 | RUNNING    | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  2000] loss: 2.298\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:53:25 (running for 00:14:00.89)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00005 | RUNNING    | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   |         |            |                      |\n",
            "| train_cifar_534cc_00006 | PENDING    |                |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00005:\n",
            "  accuracy: 0.1013\n",
            "  date: 2022-06-29_22-53-27\n",
            "  done: true\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 1\n",
            "  loss: 2.3088091270446776\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 22.638712167739868\n",
            "  time_this_iter_s: 22.638712167739868\n",
            "  time_total_s: 22.638712167739868\n",
            "  timestamp: 1656543207\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 534cc_00005\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:53:32 (running for 00:14:08.42)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.27258648853302\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00006 | RUNNING    | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:53:37 (running for 00:14:13.44)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.27258648853302\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00006 | RUNNING    | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  2000] loss: 2.302\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:53:42 (running for 00:14:18.45)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.27258648853302\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00006 | RUNNING    | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:53:47 (running for 00:14:23.46)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.27258648853302\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00006 | RUNNING    | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  4000] loss: 1.146\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:53:52 (running for 00:14:28.49)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.27258648853302\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00006 | RUNNING    | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:53:57 (running for 00:14:33.51)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.27258648853302\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00006 | RUNNING    | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 |         |            |                      |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00006:\n",
            "  accuracy: 0.1545\n",
            "  date: 2022-06-29_22-53-58\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 1\n",
            "  loss: 2.2483593413352967\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 30.489777326583862\n",
            "  time_this_iter_s: 30.489777326583862\n",
            "  time_total_s: 30.489777326583862\n",
            "  timestamp: 1656543238\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 534cc_00006\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:54:03 (running for 00:14:38.92)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2483593413352967\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00006 | RUNNING    | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.24836 |     0.1545 |                    1 |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [2,  2000] loss: 2.193\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:54:08 (running for 00:14:43.95)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2483593413352967\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00006 | RUNNING    | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.24836 |     0.1545 |                    1 |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:54:13 (running for 00:14:48.97)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2483593413352967\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00006 | RUNNING    | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.24836 |     0.1545 |                    1 |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:54:18 (running for 00:14:53.99)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2483593413352967\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00006 | RUNNING    | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.24836 |     0.1545 |                    1 |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [2,  4000] loss: 1.031\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:54:23 (running for 00:14:59.00)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2483593413352967\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00006 | RUNNING    | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.24836 |     0.1545 |                    1 |\n",
            "| train_cifar_534cc_00007 | PENDING    |                |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00006:\n",
            "  accuracy: 0.2594\n",
            "  date: 2022-06-29_22-54-28\n",
            "  done: true\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 2\n",
            "  loss: 2.005380398273468\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 60.407294511795044\n",
            "  time_this_iter_s: 29.91751718521118\n",
            "  time_total_s: 60.407294511795044\n",
            "  timestamp: 1656543268\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: 534cc_00006\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:54:33 (running for 00:15:08.89)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.2483593413352967\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:54:38 (running for 00:15:13.91)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.2483593413352967\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  2000] loss: 1.948\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:54:43 (running for 00:15:18.93)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.2483593413352967\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:54:48 (running for 00:15:23.94)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.2483593413352967\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  4000] loss: 0.807\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:54:53 (running for 00:15:28.96)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.2483593413352967\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:54:58 (running for 00:15:33.99)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.2483593413352967\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  |         |            |                      |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00007:\n",
            "  accuracy: 0.4576\n",
            "  date: 2022-06-29_22-54-59\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.5285838571071624\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 31.75348973274231\n",
            "  time_this_iter_s: 31.75348973274231\n",
            "  time_total_s: 31.75348973274231\n",
            "  timestamp: 1656543299\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 534cc_00007\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:55:04 (running for 00:15:40.66)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.52858 |     0.4576 |                    1 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:55:10 (running for 00:15:45.70)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.52858 |     0.4576 |                    1 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [2,  2000] loss: 1.465\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:55:15 (running for 00:15:50.74)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.52858 |     0.4576 |                    1 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:55:20 (running for 00:15:55.76)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.52858 |     0.4576 |                    1 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [2,  4000] loss: 0.713\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:55:25 (running for 00:16:00.78)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.52858 |     0.4576 |                    1 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:55:30 (running for 00:16:05.79)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.815007333755493 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.52858 |     0.4576 |                    1 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00007:\n",
            "  accuracy: 0.5104\n",
            "  date: 2022-06-29_22-55-30\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 2\n",
            "  loss: 1.3732785094976425\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 62.302650451660156\n",
            "  time_this_iter_s: 30.549160718917847\n",
            "  time_total_s: 62.302650451660156\n",
            "  timestamp: 1656543330\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: 534cc_00007\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:55:35 (running for 00:16:11.20)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.37328 |     0.5104 |                    2 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:55:40 (running for 00:16:16.23)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.37328 |     0.5104 |                    2 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [3,  2000] loss: 1.347\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:55:45 (running for 00:16:21.24)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.37328 |     0.5104 |                    2 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:55:50 (running for 00:16:26.25)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.37328 |     0.5104 |                    2 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [3,  4000] loss: 0.667\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:55:55 (running for 00:16:31.27)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.37328 |     0.5104 |                    2 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:56:00 (running for 00:16:36.28)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.37328 |     0.5104 |                    2 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00007:\n",
            "  accuracy: 0.4717\n",
            "  date: 2022-06-29_22-56-01\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 3\n",
            "  loss: 1.5164941629886628\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 92.84948945045471\n",
            "  time_this_iter_s: 30.546838998794556\n",
            "  time_total_s: 92.84948945045471\n",
            "  timestamp: 1656543361\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 3\n",
            "  trial_id: 534cc_00007\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:56:06 (running for 00:16:41.74)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.51649 |     0.4717 |                    3 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:56:11 (running for 00:16:46.75)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.51649 |     0.4717 |                    3 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [4,  2000] loss: 1.249\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:56:16 (running for 00:16:51.76)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.51649 |     0.4717 |                    3 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:56:21 (running for 00:16:56.79)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.51649 |     0.4717 |                    3 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [4,  4000] loss: 0.644\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:56:26 (running for 00:17:01.82)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.51649 |     0.4717 |                    3 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:56:31 (running for 00:17:06.83)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.4394416034698487 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.51649 |     0.4717 |                    3 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00007:\n",
            "  accuracy: 0.5135\n",
            "  date: 2022-06-29_22-56-31\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 4\n",
            "  loss: 1.3604382481336594\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 123.5796914100647\n",
            "  time_this_iter_s: 30.730201959609985\n",
            "  time_total_s: 123.5796914100647\n",
            "  timestamp: 1656543391\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 4\n",
            "  trial_id: 534cc_00007\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:56:36 (running for 00:17:12.48)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.36044 |     0.5135 |                    4 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:56:41 (running for 00:17:17.50)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.36044 |     0.5135 |                    4 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [5,  2000] loss: 1.167\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:56:46 (running for 00:17:22.52)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.36044 |     0.5135 |                    4 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:56:51 (running for 00:17:27.54)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.36044 |     0.5135 |                    4 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [5,  4000] loss: 0.610\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:56:56 (running for 00:17:32.55)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.36044 |     0.5135 |                    4 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:57:01 (running for 00:17:37.57)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.36044 |     0.5135 |                    4 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00007:\n",
            "  accuracy: 0.5518\n",
            "  date: 2022-06-29_22-57-02\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 5\n",
            "  loss: 1.2935756599664687\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 154.09441375732422\n",
            "  time_this_iter_s: 30.51472234725952\n",
            "  time_total_s: 154.09441375732422\n",
            "  timestamp: 1656543422\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 5\n",
            "  trial_id: 534cc_00007\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:57:07 (running for 00:17:42.97)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.29358 |     0.5518 |                    5 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:57:12 (running for 00:17:47.97)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.29358 |     0.5518 |                    5 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [6,  2000] loss: 1.160\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:57:17 (running for 00:17:52.99)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.29358 |     0.5518 |                    5 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:57:22 (running for 00:17:58.02)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.29358 |     0.5518 |                    5 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [6,  4000] loss: 0.585\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:57:27 (running for 00:18:03.03)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.29358 |     0.5518 |                    5 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:57:32 (running for 00:18:08.04)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.29358 |     0.5518 |                    5 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00007:\n",
            "  accuracy: 0.5585\n",
            "  date: 2022-06-29_22-57-34\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 6\n",
            "  loss: 1.279830942106247\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 185.93323016166687\n",
            "  time_this_iter_s: 31.83881640434265\n",
            "  time_total_s: 185.93323016166687\n",
            "  timestamp: 1656543454\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 6\n",
            "  trial_id: 534cc_00007\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:57:39 (running for 00:18:14.81)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.27983 |     0.5585 |                    6 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:57:44 (running for 00:18:19.82)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.27983 |     0.5585 |                    6 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [7,  2000] loss: 1.105\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:57:49 (running for 00:18:24.85)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.27983 |     0.5585 |                    6 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:57:54 (running for 00:18:29.86)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.27983 |     0.5585 |                    6 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [7,  4000] loss: 0.578\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:57:59 (running for 00:18:34.88)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.27983 |     0.5585 |                    6 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:58:04 (running for 00:18:39.90)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.27983 |     0.5585 |                    6 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00007:\n",
            "  accuracy: 0.5429\n",
            "  date: 2022-06-29_22-58-04\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 7\n",
            "  loss: 1.3795620621681213\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 216.61526465415955\n",
            "  time_this_iter_s: 30.682034492492676\n",
            "  time_total_s: 216.61526465415955\n",
            "  timestamp: 1656543484\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 7\n",
            "  trial_id: 534cc_00007\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:58:09 (running for 00:18:45.51)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.37956 |     0.5429 |                    7 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:58:14 (running for 00:18:50.52)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.37956 |     0.5429 |                    7 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [8,  2000] loss: 1.062\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:58:19 (running for 00:18:55.56)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.37956 |     0.5429 |                    7 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:58:24 (running for 00:19:00.58)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.37956 |     0.5429 |                    7 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [8,  4000] loss: 0.556\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:58:29 (running for 00:19:05.59)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.37956 |     0.5429 |                    7 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:58:34 (running for 00:19:10.61)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.375316877555847 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.37956 |     0.5429 |                    7 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00007:\n",
            "  accuracy: 0.5643\n",
            "  date: 2022-06-29_22-58-35\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 8\n",
            "  loss: 1.3080328577756881\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 247.2689197063446\n",
            "  time_this_iter_s: 30.65365505218506\n",
            "  time_total_s: 247.2689197063446\n",
            "  timestamp: 1656543515\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 8\n",
            "  trial_id: 534cc_00007\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:58:40 (running for 00:19:16.14)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.30803 |     0.5643 |                    8 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:58:45 (running for 00:19:21.15)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.30803 |     0.5643 |                    8 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [9,  2000] loss: 1.026\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:58:50 (running for 00:19:26.17)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.30803 |     0.5643 |                    8 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:58:55 (running for 00:19:31.20)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.30803 |     0.5643 |                    8 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [9,  4000] loss: 0.544\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:59:00 (running for 00:19:36.23)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.30803 |     0.5643 |                    8 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:59:05 (running for 00:19:41.27)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.30803 |     0.5643 |                    8 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00007:\n",
            "  accuracy: 0.5403\n",
            "  date: 2022-06-29_22-59-05\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 9\n",
            "  loss: 1.3385678907155991\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 277.8249797821045\n",
            "  time_this_iter_s: 30.556060075759888\n",
            "  time_total_s: 277.8249797821045\n",
            "  timestamp: 1656543545\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 9\n",
            "  trial_id: 534cc_00007\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:59:11 (running for 00:19:46.70)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.33857 |     0.5403 |                    9 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:59:16 (running for 00:19:51.70)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.33857 |     0.5403 |                    9 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [10,  2000] loss: 1.014\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:59:21 (running for 00:19:56.72)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.33857 |     0.5403 |                    9 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:59:26 (running for 00:20:01.73)\n",
            "Memory usage on this node: 1.7/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.33857 |     0.5403 |                    9 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [10,  4000] loss: 0.534\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:59:31 (running for 00:20:06.75)\n",
            "Memory usage on this node: 1.7/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.33857 |     0.5403 |                    9 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:59:36 (running for 00:20:11.78)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00007 | RUNNING    | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.33857 |     0.5403 |                    9 |\n",
            "| train_cifar_534cc_00008 | PENDING    |                |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00007:\n",
            "  accuracy: 0.5274\n",
            "  date: 2022-06-29_22-59-36\n",
            "  done: true\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 10\n",
            "  loss: 1.4701241670370102\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 308.754061460495\n",
            "  time_this_iter_s: 30.929081678390503\n",
            "  time_total_s: 308.754061460495\n",
            "  timestamp: 1656543576\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 10\n",
            "  trial_id: 534cc_00007\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:59:41 (running for 00:20:17.64)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  2000] loss: 2.013\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:59:46 (running for 00:20:22.66)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:59:51 (running for 00:20:27.68)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  4000] loss: 0.930\n",
            "== Status ==\n",
            "Current time: 2022-06-29 22:59:57 (running for 00:20:32.70)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  6000] loss: 0.608\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:00:02 (running for 00:20:37.72)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:00:07 (running for 00:20:42.75)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  8000] loss: 0.454\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:00:12 (running for 00:20:47.78)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1, 10000] loss: 0.363\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:00:17 (running for 00:20:52.79)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:00:22 (running for 00:20:57.81)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   |         |            |                      |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00008:\n",
            "  accuracy: 0.3219\n",
            "  date: 2022-06-29_23-00-23\n",
            "  done: false\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.8789392227649688\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 46.97835326194763\n",
            "  time_this_iter_s: 46.97835326194763\n",
            "  time_total_s: 46.97835326194763\n",
            "  timestamp: 1656543623\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 534cc_00008\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:00:28 (running for 00:21:04.62)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.87894 |     0.3219 |                    1 |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [2,  2000] loss: 1.804\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:00:33 (running for 00:21:09.63)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.87894 |     0.3219 |                    1 |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:00:38 (running for 00:21:14.64)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.87894 |     0.3219 |                    1 |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [2,  4000] loss: 0.925\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:00:43 (running for 00:21:19.66)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.87894 |     0.3219 |                    1 |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [2,  6000] loss: 0.603\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:00:48 (running for 00:21:24.67)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.87894 |     0.3219 |                    1 |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:00:54 (running for 00:21:29.69)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.87894 |     0.3219 |                    1 |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [2,  8000] loss: 0.451\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:00:59 (running for 00:21:34.70)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.87894 |     0.3219 |                    1 |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [2, 10000] loss: 0.370\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:01:04 (running for 00:21:39.71)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.87894 |     0.3219 |                    1 |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:01:09 (running for 00:21:44.73)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.6966645179748536 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00008 | RUNNING    | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.87894 |     0.3219 |                    1 |\n",
            "| train_cifar_534cc_00009 | PENDING    |                |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_534cc_00008:\n",
            "  accuracy: 0.3189\n",
            "  date: 2022-06-29_23-01-09\n",
            "  done: true\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 2\n",
            "  loss: 1.8491822976589203\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 93.00436496734619\n",
            "  time_this_iter_s: 46.02601170539856\n",
            "  time_total_s: 93.00436496734619\n",
            "  timestamp: 1656543669\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: 534cc_00008\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m Files already downloaded and verified\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:01:14 (running for 00:21:50.67)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.772923407816887 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00009 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "| train_cifar_534cc_00008 | TERMINATED | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.84918 |     0.3189 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:01:20 (running for 00:21:55.68)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.772923407816887 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00009 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "| train_cifar_534cc_00008 | TERMINATED | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.84918 |     0.3189 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:01:25 (running for 00:22:00.73)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.772923407816887 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00009 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "| train_cifar_534cc_00008 | TERMINATED | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.84918 |     0.3189 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(func pid=366)\u001b[0m [1,  2000] loss: 2.208\n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:01:30 (running for 00:22:05.74)\n",
            "Memory usage on this node: 1.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.772923407816887 | Iter 1.000: -2.2363638500213625\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00009 | RUNNING    | 172.28.0.2:366 |           16 |    8 |  256 | 0.0431248   |         |            |                      |\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "| train_cifar_534cc_00008 | TERMINATED | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.84918 |     0.3189 |                    2 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-29 23:01:33,160\tINFO tune.py:748 -- Total run time: 1328.97 seconds (1328.72 seconds for the tuning loop).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_cifar_534cc_00009:\n",
            "  accuracy: 0.1166\n",
            "  date: 2022-06-29_23-01-33\n",
            "  done: true\n",
            "  experiment_id: 426ca0e123214863a85cc570e995021e\n",
            "  hostname: 7aac40461a56\n",
            "  iterations_since_restore: 1\n",
            "  loss: 2.304917699432373\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 366\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 23.050607681274414\n",
            "  time_this_iter_s: 23.050607681274414\n",
            "  time_total_s: 23.050607681274414\n",
            "  timestamp: 1656543693\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 534cc_00009\n",
            "  warmup_time: 0.0032346248626708984\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-29 23:01:33 (running for 00:22:08.73)\n",
            "Memory usage on this node: 1.5/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=10\n",
            "Bracket: Iter 8.000: -1.3416748676657675 | Iter 4.000: -1.432748481321335 | Iter 2.000: -1.772923407816887 | Iter 1.000: -2.2423615956783296\n",
            "Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-06-29_22-39-24\n",
            "Number of trials: 10/10 (10 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status     | loc            |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_534cc_00000 | TERMINATED | 172.28.0.2:366 |           16 |  256 |  128 | 0.000336968 | 1.26607 |     0.5525 |                   10 |\n",
            "| train_cifar_534cc_00001 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.000516031 | 1.22847 |     0.5582 |                   10 |\n",
            "| train_cifar_534cc_00002 | TERMINATED | 172.28.0.2:366 |           16 |    8 |   16 | 0.00961721  | 1.45227 |     0.4804 |                    8 |\n",
            "| train_cifar_534cc_00003 | TERMINATED | 172.28.0.2:366 |            2 |  256 |    4 | 0.0782832   | 2.43687 |     0.1006 |                    1 |\n",
            "| train_cifar_534cc_00004 | TERMINATED | 172.28.0.2:366 |            2 |   16 |  128 | 0.0638543   | 2.41269 |     0.0965 |                    1 |\n",
            "| train_cifar_534cc_00005 | TERMINATED | 172.28.0.2:366 |           16 |    8 |    8 | 0.0528172   | 2.30881 |     0.1013 |                    1 |\n",
            "| train_cifar_534cc_00006 | TERMINATED | 172.28.0.2:366 |            8 |   16 |   64 | 0.000161347 | 2.00538 |     0.2594 |                    2 |\n",
            "| train_cifar_534cc_00007 | TERMINATED | 172.28.0.2:366 |            8 |  256 |   16 | 0.00492784  | 1.47012 |     0.5274 |                   10 |\n",
            "| train_cifar_534cc_00008 | TERMINATED | 172.28.0.2:366 |            4 |   16 |   64 | 0.0060132   | 1.84918 |     0.3189 |                    2 |\n",
            "| train_cifar_534cc_00009 | TERMINATED | 172.28.0.2:366 |           16 |    8 |  256 | 0.0431248   | 2.30492 |     0.1166 |                    1 |\n",
            "+-------------------------+------------+----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Best trial config: {'l1': 8, 'l2': 256, 'lr': 0.0005160314904159941, 'batch_size': 16}\n",
            "Best trial final validation loss: 1.2284743344306945\n",
            "Best trial final validation accuracy: 0.5582\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Best trial test set accuracy: 0.569\n"
          ]
        }
      ],
      "source": [
        "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
        "    data_dir = os.path.abspath(\"./data\")\n",
        "    load_data(data_dir)\n",
        "    config = {\n",
        "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
        "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
        "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "        \"batch_size\": tune.choice([2, 4, 8, 16])\n",
        "    }\n",
        "    scheduler = ASHAScheduler(\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=max_num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "    reporter = CLIReporter(\n",
        "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
        "    result = tune.run(\n",
        "        partial(train_cifar, data_dir=data_dir),\n",
        "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter)\n",
        "\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\n",
        "    print(\"Best trial final validation loss: {}\".format(\n",
        "        best_trial.last_result[\"loss\"]))\n",
        "    print(\"Best trial final validation accuracy: {}\".format(\n",
        "        best_trial.last_result[\"accuracy\"]))\n",
        "\n",
        "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if gpus_per_trial > 1:\n",
        "            best_trained_model = nn.DataParallel(best_trained_model)\n",
        "    best_trained_model.to(device)\n",
        "\n",
        "    best_checkpoint_dir = best_trial.checkpoint.value\n",
        "    model_state, optimizer_state = torch.load(os.path.join(\n",
        "        best_checkpoint_dir, \"checkpoint\"))\n",
        "    best_trained_model.load_state_dict(model_state)\n",
        "\n",
        "    test_acc = test_accuracy(best_trained_model, device)\n",
        "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # You can change the number of GPUs per trial here:\n",
        "    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z7HPKk2lhIF"
      },
      "source": [
        "If you run the code, an example output could look like this:\n",
        "\n",
        "::\n",
        "\n",
        "    Number of trials: 10 (10 TERMINATED)\n",
        "    +-----+------+------+-------------+--------------+---------+------------+--------------------+\n",
        "    | ... |   l1 |   l2 |          lr |   batch_size |    loss |   accuracy | training_iteration |\n",
        "    |-----+------+------+-------------+--------------+---------+------------+--------------------|\n",
        "    | ... |   64 |    4 | 0.00011629  |            2 | 1.87273 |     0.244  |                  2 |\n",
        "    | ... |   32 |   64 | 0.000339763 |            8 | 1.23603 |     0.567  |                  8 |\n",
        "    | ... |    8 |   16 | 0.00276249  |           16 | 1.1815  |     0.5836 |                 10 |\n",
        "    | ... |    4 |   64 | 0.000648721 |            4 | 1.31131 |     0.5224 |                  8 |\n",
        "    | ... |   32 |   16 | 0.000340753 |            8 | 1.26454 |     0.5444 |                  8 |\n",
        "    | ... |    8 |    4 | 0.000699775 |            8 | 1.99594 |     0.1983 |                  2 |\n",
        "    | ... |  256 |    8 | 0.0839654   |           16 | 2.3119  |     0.0993 |                  1 |\n",
        "    | ... |   16 |  128 | 0.0758154   |           16 | 2.33575 |     0.1327 |                  1 |\n",
        "    | ... |   16 |    8 | 0.0763312   |           16 | 2.31129 |     0.1042 |                  4 |\n",
        "    | ... |  128 |   16 | 0.000124903 |            4 | 2.26917 |     0.1945 |                  1 |\n",
        "    +-----+------+------+-------------+--------------+---------+------------+--------------------+\n",
        "\n",
        "\n",
        "    Best trial config: {'l1': 8, 'l2': 16, 'lr': 0.00276249, 'batch_size': 16, 'data_dir': '...'}\n",
        "    Best trial final validation loss: 1.181501\n",
        "    Best trial final validation accuracy: 0.5836\n",
        "    Best trial test set accuracy: 0.5806\n",
        "\n",
        "Most trials have been stopped early in order to avoid wasting resources.\n",
        "The best performing trial achieved a validation accuracy of about 58%, which could\n",
        "be confirmed on the test set.\n",
        "\n",
        "So that's it! You can now tune the parameters of your PyTorch models.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "name": "hyperparameter_tuning_tutorial.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d0271b98b0e435ba372875bfaab4f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bd7a55073354c7b80973b1f9482cc4f",
              "IPY_MODEL_c3234dabe956409ebb66139974ba4a30",
              "IPY_MODEL_a0bcca8600de47a396327e32371c8be2"
            ],
            "layout": "IPY_MODEL_6c46fa64ca7b4a5780ecacec061f03d7"
          }
        },
        "8bd7a55073354c7b80973b1f9482cc4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_241f01ef828c455ab4cb40b34b4ec7a3",
            "placeholder": "​",
            "style": "IPY_MODEL_c037dd43599a42749cea28bfb02fd7fa",
            "value": ""
          }
        },
        "c3234dabe956409ebb66139974ba4a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_201cfbff90a348b9b6e2cc813fa0c7a7",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_429f310f63d94692a1f247ce33403cde",
            "value": 170498071
          }
        },
        "a0bcca8600de47a396327e32371c8be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_543888956c3c4071bff62c2c0df0179e",
            "placeholder": "​",
            "style": "IPY_MODEL_f5a91ee4187d4d259f3696950c05c034",
            "value": " 170499072/? [00:04&lt;00:00, 52978906.64it/s]"
          }
        },
        "6c46fa64ca7b4a5780ecacec061f03d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "241f01ef828c455ab4cb40b34b4ec7a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c037dd43599a42749cea28bfb02fd7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "201cfbff90a348b9b6e2cc813fa0c7a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "429f310f63d94692a1f247ce33403cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "543888956c3c4071bff62c2c0df0179e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a91ee4187d4d259f3696950c05c034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}